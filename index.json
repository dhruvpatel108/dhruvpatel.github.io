[{"authors":["admin"],"categories":null,"content":"I am a PhD. candidate in Aerospace and Mechanical Engineering department at USC advised by Prof. Assad Oberai.\nMy research interest lies at the intersection of physics-based and data-driven modeling, deep generative modeling, inverse problems, and uncertainty quantification with applications to computational science and engineering, computer vision, and medical imaging. I am particularly interested in the question of how to optimally combine physics-guided models with modern machine learning algorithms to develop more data efficient and accurate hybrid models.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dhruvpatel.github.io/author/dhruv-patel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dhruv-patel/","section":"authors","summary":"I am a PhD. candidate in Aerospace and Mechanical Engineering department at USC advised by Prof. Assad Oberai.\nMy research interest lies at the intersection of physics-based and data-driven modeling, deep generative modeling, inverse problems, and uncertainty quantification with applications to computational science and engineering, computer vision, and medical imaging.","tags":null,"title":"Dhruv Patel","type":"authors"},{"authors":["Dhruv Patel","Ravi Bonam","Assad Oberai"],"categories":null,"content":"","date":1587366000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587366000,"objectID":"33ea702e6c90fc577ba4d88cf0af69b4","permalink":"https://dhruvpatel.github.io/publication/jm3/","publishdate":"2020-04-20T00:00:00-07:00","relpermalink":"/publication/jm3/","section":"publication","summary":"Defects in semiconductor processes can limit yield, increase overall production cost, and also lead to time-dependent critical component failures. Current state-of-the-art optical and electron beam (EB) inspection systems rely on rule-based techniques for defect detection and classification, which are usually rigid in their comparative processes. This rigidity limits overall capability and increases relative engineering time to classify nuisance defects. This is further challenged due to shrinkage of pattern dimensions for advanced nodes. We propose a deep learning-based workflow that circumvents these challenges and enables accurate defect detection, classification, and localization in a unified framework. In particular, we train convolutional neural network-based models using high-resolution EB images of wafers patterned with various types of intentional defects and achieve robust defect detection and classification performance. Furthermore, we generate class activation maps to demonstrate defect localization capability of the model “without” explicitly training it with defect location information. To understand the underlying decision-making process of these deep models, we analyze the learned filters in pixel space and Fourier space and interpret the various operations at different layers. We achieve high sensitivity (97%) and specificity (100%) along with rapid and accurate defect localization. We also test performance of the proposed workflow on images from two distinct patterns and find that in order to retain high accuracy a modest level of retraining is necessary.","tags":[],"title":"Deep Learning-based Detection, Classification, and Localization of Defects in Semiconductor Processes","type":"publication"},{"authors":["Dhruv Patel","Assad Oberai"],"categories":null,"content":"","date":1568444400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568444400,"objectID":"3ee6ae93c8316ae5e58adb1bcf14167c","permalink":"https://dhruvpatel.github.io/publication/neurips19/","publishdate":"2019-09-14T00:00:00-07:00","relpermalink":"/publication/neurips19/","section":"publication","summary":"Bayesian inference is used extensively to infer and to quantify the uncertainty in a field of interest from a measurement of a related field when the two are linked by a mathematical model. Despite its many applications, Bayesian inference faces challenges when inferring fields that have discrete representations of large dimension, and/or have prior distributions that are difficult to characterize mathematically. In this work we demonstrate how the approximate distribution learned by a generative adversarial network (GAN) may be used as a prior in a Bayesian update to address both these challenges. We demonstrate the efficacy of this approach by inferring and quantifying uncertainty in a physics-based inverse problem and an inverse problem arising in computer vision. In this latter example, we also demonstrate how the knowledge of the spatial variation of uncertainty may be used to select an optimal strategy of placing the sensors (i.e. taking measurements), where information about the image is revealed one sub-region at a time.","tags":[],"title":"GAN Priors for Bayesian Inference","type":"publication"},{"authors":null,"categories":null,"content":"Summary:\n Breast ultrasound elastography is a non-invasive technique used by radiologists to help detect and diagnose cancer and other diseases by evaluating a lesion\u0026rsquo;s stiffness in a non-invasive way. Researchers identified the critical role machine learning can play in making this technique more efficient and accurate in diagnosis.\n Breast cancer is the leading cause of cancer-related death among women. It is also difficult to diagnose. Nearly one in 10 cancers is misdiagnosed as not cancerous, meaning that a patient can lose critical treatment time. On the other hand, the more mammograms a woman has, the more likely it is she will see a false positive result. After 10 years of annual mammograms, roughly two out of three patients who do not have cancer will be told that they do and be subjected to an invasive intervention, most likely a biopsy.\nBreast ultrasound elastography is an emerging imaging technique that provides information about a potential breast lesion by evaluating its stiffness in a non-invasive way. Using more precise information about the characteristics of a cancerous versus non-cancerous breast lesion, this methodology has demonstrated more accuracy compared to traditional modes of imaging.\nAt the crux of this procedure, however, is a complex computational problem that can be time-consuming and cumbersome to solve. But what if instead we relied on the guidance of an algorithm?\nAssad Oberai, USC Viterbi School of Engineering Hughes Professor in the Department of Aerospace and Mechanical Engineering, asked this exact question in the research paper, \u0026ldquo;Circumventing the solution of inverse problems in mechanics through deep learning: application to elasticity imaging,\u0026rdquo; published in Computer Methods in Applied Mechanics and Engineering. Along with a team of researchers, including USC Viterbi Ph.D student Dhruv Patel, Oberai specifically considered the following: Can you train a machine to interpret real-world images using synthetic data and streamline the steps to diagnosis? The answer, Oberai says, is most likely yes.\nIn the case of breast ultrasound elastography, once an image of the affected area is taken, the image is analyzed to determine displacements inside the tissue. Using this data and the physical laws of mechanics, the spatial distribution of mechanical properties \u0026ndash; like its stiffness \u0026ndash; is determined. After this, one has to identify and quantify the appropriate features from the distribution, ultimately leading to a classification of the tumor as malignant or benign. The problem is the final two steps are computationally complex and inherently challenging.\nIn the research, Oberai sought to determine if they could skip the most complicated steps of this workflow entirely.\nCancerous breast tissue has two key properties: heterogeneity, which means some areas are soft and some are firm, and non-linear elasticity, which means the fibers offer a lot of resistance when pulled instead of the initial give associated with benign tumors. Knowing this, Oberai created physics-based models that showed varying levels of these key properties. He then used thousands of data inputs derived from these models in order to train the machine learning algorithm.\nSynthetic Versus Real-World Data\nBut why would you use synthetically-derived data to train the algorithm? Wouldn\u0026rsquo;t real data be better?\n\u0026ldquo;If you had enough data available, you wouldn\u0026rsquo;t,\u0026rdquo; said Oberai. \u0026ldquo;But in the case of medical imaging, you\u0026rsquo;re lucky if you have 1,000 images. In situations like this where data is scarce, these kinds of techniques become important.\u0026rdquo;\nOberai and his team used about 12,000 synthetic images to train their machine learning algorithm. This process is similar in many ways to how photo identification software works, learning through repeated inputs how to recognize a particular person in an image, or how our brain learns to classify a cat versus a dog. Through enough examples, the algorithm is able to glean different features inherent to a benign tumor versus a malignant tumor and make the correct determination.\nOberai and his team achieved nearly 100 percent classification accuracy on other synthetic images. Once the algorithm was trained, they tested it on real-world images to determine how accurate it could be in providing a diagnosis, measuring these results against biopsy-confirmed diagnoses associated with these images.\n\u0026ldquo;We had about an 80 percent accuracy rate. Next, we continue to refine the algorithm by using more real-world images as inputs,\u0026rdquo; Oberai said.\nChanging How Diagnoses are Made\nThere are two prevailing points that make machine learning an important tool in advancing the landscape for cancer detection and diagnosis. First, machine learning algorithms can detect patterns that might be opaque to humans. Through manipulation of many such patterns, the algorithm can produce an accurate diagnosis. Secondly, machine learning offers a chance to reduce operator-to-operator error.\nSo then, would this replace a radiologist\u0026rsquo;s role in determining diagnosis? Definitely not. Oberai does not foresee an algorithm that serves as a sole arbiter of cancer diagnosis, but instead, a tool that helps guide radiologists to more accurate conclusions. \u0026ldquo;The general consensus is these types of algorithms have a significant role to play, including from imaging professionals whom it will impact the most. However, these algorithms will be most useful when they do not serve as black boxes,\u0026rdquo; said Oberai. \u0026ldquo;What did it see that led it to the final conclusion? The algorithm must be explainable for it to work as intended.\u0026rdquo;\nAdapting the Algorithm for Other Cancers\nBecause cancer causes different types of changes in the tissue it impacts, the presence of cancer in a tissue can ultimately lead to a change in its physical properties, for example a change in density or porosity. These changes are can be discerned as a signal in medical images. The role of the machine learning algorithm is to pick out this signal and use it to determine whether a given tissue that is being imaged is cancerous.\nUsing these ideas, Oberai and his team are working with Vinay Duddalwar, professor of clinical radiology at the Keck School of Medicine of USC, to better diagnose renal cancer through contrast enhanced CT images. Using the principles identified in training the machine learning algorithm for breast cancer diagnosis, they are looking to train the algorithm on other features that might be prominently displayed in renal cancer cases, such as changes in tissue that reflect cancer-specific changes in a patient\u0026rsquo;s microvasculature, the network of microvessels that help distribute blood within tissues.\n","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"1f465a5aceea844688c7cd47284be362","permalink":"https://dhruvpatel.github.io/post/circumventing_inverse_problem/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/circumventing_inverse_problem/","section":"post","summary":"Summary:\n Breast ultrasound elastography is a non-invasive technique used by radiologists to help detect and diagnose cancer and other diseases by evaluating a lesion\u0026rsquo;s stiffness in a non-invasive way. Researchers identified the critical role machine learning can play in making this technique more efficient and accurate in diagnosis.","tags":null,"title":"How AI can be used for quick and accurate non-invasive detection of breast cancer?","type":"post"},{"authors":["Dhruv Patel","Raghav Tibrewala","Adriana Vega","Li Dong","Nicholas Hugenberg","Assad Oberai"],"categories":null,"content":"","date":1499238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499238000,"objectID":"9a206d7833664e63e7b3a16eee9b3651","permalink":"https://dhruvpatel.github.io/publication/cmame/","publishdate":"2017-07-05T00:00:00-07:00","relpermalink":"/publication/cmame/","section":"publication","summary":"The ability to make decisions based on quantities of interest that depend on variables inferred from measurement finds application in different fields of mechanics and physics. The evaluation of the inferred variables, and hence the quantities of interest, from the measurement typically requires the solution of an inverse problem. For example, in medical imaging the elastic heterogeneity of a tumor and its nonlinear elastic response can be used to distinguish benign tumors from their malignant counterparts. These images of linear and nonlinear elastic parameters of tissue are typically obtained by using a measured displacement field and solving a complex inverse elasticity problem. In this paper we consider circumventing the solution of the inverse problem by using measured displacements as input to a deep convolutional neural network (CNN) and training it to classify tumors on the basis of their elastic heterogeneity and nonlinearity. For a simple, 5-layer CNN trained with 8,000 samples for heterogeneity, and a 4-layer CNN trained with 4,000 samples for nonlinear elasticity we report classification accuracies in the range of 99.7% - 99.9%. The training and testing data are both obtained from the forward solution of finite element models of samples. We also analyze the weights of the trained model to understand the process through which the network extracts features of elastic moduli from the input displacement images. Finally, we apply the nonlinear elasticity classifier, which is trained entirely using simulated data, to displacement images obtained from ten patients with breast lesions and note that it correctly classifies eight out of ten cases. This application illustrates how data from physics-based models can be used in improving the performance of a data-driven algorithm in data-sparse scenarios.","tags":[],"title":"Circumventing the Solution of Inverse Problems in Mechanics through Deep Learning: Application to Elasticity Imaging","type":"publication"},{"authors":["Dhruv Patel","Ravi Bonam","Assad Oberai"],"categories":null,"content":"","date":1499238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499238000,"objectID":"d756dc99c1d88930959d7e7aabfcd2f0","permalink":"https://dhruvpatel.github.io/publication/spie/","publishdate":"2017-07-05T00:00:00-07:00","relpermalink":"/publication/spie/","section":"publication","summary":"Defects are ubiquitous in semiconductor industry, and their detection, classification, and localization at various levels is a challenge that requires rigorous sampling. Current state-of-the art optical and e-beam inspection systems based on gray-scale diverences for detection and rule-based binning for classfication are rigid and are not invariant to defect type, size, and substrate material. Furthermore, every new technology offers a new challenge and requires numerous hours of setup, debugging, and manual tuning of process parameters by integrated chip manufacturers. In this work, we propose a deep-learning based work ow which circumvents these challenges and enables accurate defect detection, classification, and localization in a single framework. In particular, we train a convolutional neural network (CNN) using high resolution e-beam images of wafers patterned with various types of intentional defects and achieve high detection and classification accuracy. Furthermore, we analyze the convolution filters and their corresponding activation maps to understand the underlying decision-making process of the deep model. To interpret the network predictions, we further generate class activation maps highlighting the focus region of model while making a prediction. This classification-trained model also showcases remarkable defect localization ability, despite not being explicitly trained for that. High sensitivity (97%) and high specificity (100%) along with rapid and accurate defect localization ability of this model demonstrate its potential for deployment in production line. ","tags":[],"title":"Engineering neural networks for improved defect detection and classification","type":"publication"},{"authors":["Dhruv Patel","Assad Oberai"],"categories":null,"content":"","date":1499238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499238000,"objectID":"c1ec6188c6d6827c3031c2a95f3b6c59","permalink":"https://dhruvpatel.github.io/publication/arxiv2/","publishdate":"2017-07-05T00:00:00-07:00","relpermalink":"/publication/arxiv2/","section":"publication","summary":"Bayesian inference is used extensively to quantify the uncertainty in an inferred field given the measurement of a related field when the two are linked by a mathematical model. Despite its many applications, Bayesian inference faces challenges when inferring fields that have discrete representations of large dimension, and/or have prior distributions that are difficult to characterize mathematically. In this work we demonstrate how the approximate distribution learned by a deep generative adversarial network (GAN) may be used as a prior in a Bayesian update to address both these challenges. We demonstrate the efficacy of this approach on two distinct, and remarkably broad, classes of problems. The first class leads to supervised learning algorithms for image classification with superior out of distribution detection and accuracy, and for image inpainting with built-in variance estimation. The second class leads to unsupervised learning algorithms for image denoising and for solving physics-driven inverse problems.","tags":[],"title":"GAN-based Priors for Quantifying Uncertainty","type":"publication"}]