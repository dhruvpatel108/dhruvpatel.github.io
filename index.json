[{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dhruvpatel.github.io/author/nelson-bighetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nelson-bighetti/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["Dhruv Patel","Ravi Bonam","Assad Oberai"],"categories":null,"content":"","date":1587366000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587366000,"objectID":"33ea702e6c90fc577ba4d88cf0af69b4","permalink":"https://dhruvpatel.github.io/publication/jm3/","publishdate":"2020-04-20T00:00:00-07:00","relpermalink":"/publication/jm3/","section":"publication","summary":"Defects in semiconductor processes can limit yield, increase overall production cost, and also lead to time-dependent critical component failures. Current state-of-the-art optical and electron beam (EB) inspection systems rely on rule-based techniques for defect detection and classification, which are usually rigid in their comparative processes. This rigidity limits overall capability and increases relative engineering time to classify nuisance defects. This is further challenged due to shrinkage of pattern dimensions for advanced nodes. We propose a deep learning-based workflow that circumvents these challenges and enables accurate defect detection, classification, and localization in a unified framework. In particular, we train convolutional neural network-based models using high-resolution EB images of wafers patterned with various types of intentional defects and achieve robust defect detection and classification performance. Furthermore, we generate class activation maps to demonstrate defect localization capability of the model “without” explicitly training it with defect location information. To understand the underlying decision-making process of these deep models, we analyze the learned filters in pixel space and Fourier space and interpret the various operations at different layers. We achieve high sensitivity (97%) and specificity (100%) along with rapid and accurate defect localization. We also test performance of the proposed workflow on images from two distinct patterns and find that in order to retain high accuracy a modest level of retraining is necessary.","tags":[],"title":"Deep Learning-based Detection, Classification, and Localization of Defects in Semiconductor Processes","type":"publication"},{"authors":["Dhruv Patel","Raghav Tibrewala","Adriana Vega","Li Dong","Nicholas Hugenberg","Assad Oberai"],"categories":null,"content":"","date":1499238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499238000,"objectID":"9a206d7833664e63e7b3a16eee9b3651","permalink":"https://dhruvpatel.github.io/publication/cmame/","publishdate":"2017-07-05T00:00:00-07:00","relpermalink":"/publication/cmame/","section":"publication","summary":"The ability to make decisions based on quantities of interest that depend on variables inferred from measurement finds application in different fields of mechanics and physics. The evaluation of the inferred variables, and hence the quantities of interest, from the measurement typically requires the solution of an inverse problem. For example, in medical imaging the elastic heterogeneity of a tumor and its nonlinear elastic response can be used to distinguish benign tumors from their malignant counterparts. These images of linear and nonlinear elastic parameters of tissue are typically obtained by using a measured displacement field and solving a complex inverse elasticity problem. In this paper we consider circumventing the solution of the inverse problem by using measured displacements as input to a deep convolutional neural network (CNN) and training it to classify tumors on the basis of their elastic heterogeneity and nonlinearity. For a simple, 5-layer CNN trained with 8,000 samples for heterogeneity, and a 4-layer CNN trained with 4,000 samples for nonlinear elasticity we report classification accuracies in the range of 99.7% - 99.9%. The training and testing data are both obtained from the forward solution of finite element models of samples. We also analyze the weights of the trained model to understand the process through which the network extracts features of elastic moduli from the input displacement images. Finally, we apply the nonlinear elasticity classifier, which is trained entirely using simulated data, to displacement images obtained from ten patients with breast lesions and note that it correctly classifies eight out of ten cases. This application illustrates how data from physics-based models can be used in improving the performance of a data-driven algorithm in data-sparse scenarios.","tags":[],"title":"Circumventing the Solution of Inverse Problems in Mechanics through Deep Learning: Application to Elasticity Imaging","type":"publication"},{"authors":["Dhruv Patel","Ravi Bonam","Assad Oberai"],"categories":null,"content":"","date":1499238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499238000,"objectID":"d756dc99c1d88930959d7e7aabfcd2f0","permalink":"https://dhruvpatel.github.io/publication/spie/","publishdate":"2017-07-05T00:00:00-07:00","relpermalink":"/publication/spie/","section":"publication","summary":"Defects are ubiquitous in semiconductor industry, and their detection, classification, and localization at various levels is a challenge that requires rigorous sampling. Current state-of-the art optical and e-beam inspection systems based on gray-scale diverences for detection and rule-based binning for classfication are rigid and are not invariant to defect type, size, and substrate material. Furthermore, every new technology offers a new challenge and requires numerous hours of setup, debugging, and manual tuning of process parameters by integrated chip manufacturers. In this work, we propose a deep-learning based work ow which circumvents these challenges and enables accurate defect detection, classification, and localization in a single framework. In particular, we train a convolutional neural network (CNN) using high resolution e-beam images of wafers patterned with various types of intentional defects and achieve high detection and classification accuracy. Furthermore, we analyze the convolution filters and their corresponding activation maps to understand the underlying decision-making process of the deep model. To interpret the network predictions, we further generate class activation maps highlighting the focus region of model while making a prediction. This classification-trained model also showcases remarkable defect localization ability, despite not being explicitly trained for that. High sensitivity (97%) and high specificity (100%) along with rapid and accurate defect localization ability of this model demonstrate its potential for deployment in production line. ","tags":[],"title":"Engineering neural networks for improved defect detection and classification","type":"publication"},{"authors":["Dhruv Patel","Assad Oberai"],"categories":null,"content":"","date":1499238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499238000,"objectID":"c1ec6188c6d6827c3031c2a95f3b6c59","permalink":"https://dhruvpatel.github.io/publication/arxiv2/","publishdate":"2017-07-05T00:00:00-07:00","relpermalink":"/publication/arxiv2/","section":"publication","summary":"Bayesian inference is used extensively to quantify the uncertainty in an inferred field given the measurement of a related field when the two are linked by a mathematical model. Despite its many applications, Bayesian inference faces challenges when inferring fields that have discrete representations of large dimension, and/or have prior distributions that are difficult to characterize mathematically. In this work we demonstrate how the approximate distribution learned by a deep generative adversarial network (GAN) may be used as a prior in a Bayesian update to address both these challenges. We demonstrate the efficacy of this approach on two distinct, and remarkably broad, classes of problems. The first class leads to supervised learning algorithms for image classification with superior out of distribution detection and accuracy, and for image inpainting with built-in variance estimation. The second class leads to unsupervised learning algorithms for image denoising and for solving physics-driven inverse problems.","tags":[],"title":"GAN-based Priors for Quantifying Uncertainty","type":"publication"}]